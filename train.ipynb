{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "Apart from standard libraries, I am one custom module \"custom_transformations\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c8d0a044f3c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElasticNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn_pandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from baikal import make_step, Step, Input, Model\n",
    "from baikal.steps import Stack\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn_pandas import gen_features\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from custom_transformations import ConcatDataFrame, CatBoostRegressorStep\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the categorical columns in the dataset\n",
    "CATEGORICAL_COLUMNS = [\n",
    "    'KitchenQual', 'MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', \n",
    "    'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', \n",
    "    'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', \n",
    "    'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', \n",
    "    'Heating', 'HeatingQC', 'CentralAir', 'Functional', 'FireplaceQu', 'GarageType', \n",
    "    'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', \n",
    "    'SaleCondition',\n",
    "    'OverallQual', 'OverallCond',\n",
    "]\n",
    "\n",
    "# these columns will be terated as a numerical columns\n",
    "NUMERICAL_COLUMNS = [\n",
    "    'LotFrontage', 'LotArea', 'YearBuilt', \n",
    "    'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "    '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "    'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', \n",
    "    'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', \n",
    "    '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold'\n",
    "]\n",
    "\n",
    "\n",
    "# These columns have missing values and the one for which we will add missing indicator variable\n",
    "MISSING_INDICATOR = [\n",
    "    'LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "    'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', \n",
    "    'GarageCond', 'PoolQC', 'Fence', 'MiscFeature'\n",
    "]\n",
    "\n",
    "## Categorical Columns for which we want One Hot Encoding\n",
    "ONEHOT_COLUMNS = [\n",
    "    'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', \n",
    "    'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', \n",
    "    'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', \n",
    "    'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', \n",
    "    'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', \n",
    "    'SaleType', 'SaleCondition'\n",
    "]\n",
    "\n",
    "## Categorical Columns for which we want to have target encoding\n",
    "TARGET_COLUMNS = [\n",
    "    'MSSubClass', 'Neighborhood', 'Exterior1st', 'Exterior2nd'\n",
    "]\n",
    "\n",
    "## Columns for that require log transformations\n",
    "LOG_COLUMNS = [\n",
    "    'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "    '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', \n",
    "    '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Steps \n",
    "ElasticNetStep = make_step(ElasticNet, class_name='ElasticNet')\n",
    "ConcatStep = make_step(ConcatDataFrame, class_name='Concat')\n",
    "XGBRegressorStep = make_step(XGBRegressor, class_name='XGBRegressor')\n",
    "LinearRegressionStep = make_step(LinearRegression, class_name='LinearRegression')\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "DataFrameMapperStep = make_step(DataFrameMapper, class_name='DataFrameMapperStep')\n",
    "\n",
    "# Define sklearn-pandas transformations. Here I am using gen_features utility to \n",
    "# define transformations for individual columns. \n",
    "baseProcessing = (\n",
    "    gen_features(\n",
    "        columns=[[x] for x in MISSING_INDICATOR],\n",
    "        classes = [\n",
    "            {'class': MissingIndicator, 'features': 'all', 'sparse': False, 'error_on_new': False}\n",
    "        ], \n",
    "        prefix = 'na_'\n",
    "    ) +\n",
    "    gen_features(\n",
    "        columns=LOG_COLUMNS,\n",
    "        classes=[\n",
    "            {'class': FunctionTransformer, 'func': lambda x: x.astype(np.float).reshape((-1, 1))},\n",
    "            {'class': SimpleImputer, 'strategy': 'mean'},\n",
    "            {'class': FunctionTransformer, 'func': np.log1p}            \n",
    "        ]\n",
    "    ) +\n",
    "    gen_features(\n",
    "        columns=list(set(NUMERICAL_COLUMNS) - set(LOG_COLUMNS)),\n",
    "        classes=[\n",
    "            {'class': FunctionTransformer, 'func': lambda x: x.astype(np.float).reshape((-1, 1))},\n",
    "            {'class': SimpleImputer, 'strategy': 'mean'}\n",
    "        ],\n",
    "    ) + \n",
    "    [\n",
    "        # constructing new features -- age of the house\n",
    "        (\n",
    "            ['YrSold', 'YearBuilt'], \n",
    "            [\n",
    "                FunctionTransformer(func=lambda x: np.clip(x[:,0] - x[:,1], 0, 1000)), \n",
    "                FunctionTransformer(np.log1p)\n",
    "            ], \n",
    "            {'alias': 'age'}\n",
    "        ),\n",
    "\n",
    "        # constructing new feature -- remodeling age\n",
    "        (\n",
    "            ['YrSold', 'YearRemodAdd'], \n",
    "            [\n",
    "                FunctionTransformer(func=lambda x: np.clip(x[:,0] - x[:,1], 0, 1000)), \n",
    "                FunctionTransformer(np.log1p)\n",
    "            ], \n",
    "            {'alias': 'remodel_age'}\n",
    "        ),\n",
    "\n",
    "        # new feature -- total surface area\n",
    "        (\n",
    "            ['1stFlrSF', '2ndFlrSF', 'TotalBsmtSF'], \n",
    "            [\n",
    "                FunctionTransformer(lambda x: np.nansum(x, axis=1)), \n",
    "                FunctionTransformer(np.log1p)\n",
    "            ], \n",
    "            {'alias': 'numerical_TotalArea'}\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Since CatBoost model can handle categorical data, we don't need to encode categorical variables\n",
    "# we will simply impute missing values and let CatBoost model handle categorical data. \n",
    "catModelPreprocessing = gen_features(\n",
    "    columns=CATEGORICAL_COLUMNS,\n",
    "    classes = [\n",
    "        {'class': FunctionTransformer, 'func': lambda x: x.astype(np.object).reshape(-1, 1)},\n",
    "        {'class': SimpleImputer, 'strategy': 'most_frequent'}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# for regression and XGBoost, we will need to encode categorical variables ourselfs. \n",
    "# Depending on the cardinality of the variable, I am either using one hot encoding or target encoding. \n",
    "regressionModelProcessing = (\n",
    "     gen_features(\n",
    "        columns=[[x] for x in ONEHOT_COLUMNS],\n",
    "        classes = [\n",
    "            {'class': OneHotEncoder, 'handle_unknown': 'ignore', 'sparse': False}\n",
    "        ]\n",
    "    ) + \n",
    "    gen_features(\n",
    "        columns=[[x] for x in TARGET_COLUMNS],\n",
    "        classes = [\n",
    "            {'class': TargetEncoder},\n",
    "            {'class': SimpleImputer, 'strategy': 'mean'},\n",
    "        ]     \n",
    "    )\n",
    ")\n",
    "    \n",
    "# Define DAG \n",
    "x = Input(name=\"x\")\n",
    "y = Input(name='y')\n",
    "\n",
    "# Define feature transformations\n",
    "d0 = DataFrameMapperStep(baseProcessing, df_out=True, name='BasePreprocess')(x, y)\n",
    "d1 = DataFrameMapperStep(regressionModelProcessing, df_out=True, name='RegressionModelPreprocess')(x, y)\n",
    "d2 = DataFrameMapperStep(catModelPreprocessing, df_out=True, name='CatModelPreprocess')(x, y)\n",
    "\n",
    "# Consolidate features for catboost and elasticnet\n",
    "regressionFeatures = ConcatStep(name='RegressionFeatures')([d0, d1])\n",
    "catFeatures = ConcatStep(name='CatBoostFeatures')([d0, d2])\n",
    "\n",
    "# Generate predictions using three different algorithms.\n",
    "m1 = ElasticNetStep(name='ElasticNet')(regressionFeatures, y)\n",
    "m2 = XGBRegressorStep(name='XGBoost')(regressionFeatures, y)\n",
    "m3 = CatBoostRegressorStep(name='CatBoost', cat_features=CATEGORICAL_COLUMNS, iterations=10)(catFeatures, y)\n",
    "\n",
    "# combine predictions from the three models\n",
    "combinedPredictions= Stack(name='CombinePredictions')([m1, m3])\n",
    "\n",
    "# construct an ensemble model\n",
    "ensembleModel = LinearRegressionStep()(combinedPredictions, y)\n",
    "model = Model(x, ensembleModel, y)\n",
    "model.fit(data, data['SalePrice'])\n",
    "\n",
    "# serialize model\n",
    "import cloudpickle\n",
    "with open('resources/model.pkl', 'wb+') as fp:\n",
    "    cloudpickle.dump(model, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baikal.plot import plot_model\n",
    "from IPython.display import SVG\n",
    "plot_model(model, filename='resources/model.svg')\n",
    "SVG('resources/model.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('metaflow': conda)",
   "metadata": {
    "interpreter": {
     "hash": "814ba462121a587853fe8e53b70f9ed373d04441f40f1f5f723d1eed8e1ca596"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}